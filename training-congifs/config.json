{
  "paths" : {
    "main_path" : "data",
    "train_path" : "%main_path%/train_mini_bert.jsonl",
    "dev_path" : "%main_path%/dev_mini_bert.jsonl",
    "tokenizer_path" :"%main_path%/tokenizer.json",
    "model_folder" : "%main_path%/saved",
    "pretrained" : ""
  },

  "model-options": {
    "model_type" : "roberta-base",
    "resume-from-checkpoint": false,
    "output_from_model": true,
    "save_each_epoch": true
  },

  "training-options": {
    "num_train_epochs" : 2,
    "per_device_train_batch_size" : 8,
    "per_device_eval_batch_size" : 8,
    "learning_rate" : 0.00005,
    "weight_decay" : 0,
    "warmup_steps" : 2000,

    "save_steps" : 50000,
    "eval_steps" : 50000,
    "save_total_limit" : 1,
    "load_best_model_at_end" : false,
    "overwrite_output_dir" : true,
    "evaluation_strategy" : "epoch"
  },

  "misc": {
      "encoded_file_keyword" : "_encoded_",
      "default_gen_input" : ""
  },

  "tokenizer_training": {
    "path" : "C:/gpt2/tokenizer/",
    "size": 49152,
    "freq": 2,
    "special_tokens": ["<s>", "<pad>", "</s>", "<unk>", "<mask>"],
    "unk_token": "<UNK>",
    "type": "BPE"
  }
}
